{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Mineração de *Tweets*\n",
    "Dados coletados durante o domingo (17/04/2015) de votação do Congresso para a continuação do processo de Impeachment da senhora Presidente Dilma Rousseff.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import folium\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import nltk\n",
    "import operator \n",
    "import os\n",
    "import pandas as pd\n",
    "# import pytz\n",
    "import random\n",
    "import re\n",
    "# import seaborn as sns\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import vincent\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from matplotlib import dates\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "# from mpltools import style\n",
    "# from nltk import FreqDist\n",
    "# from nltk import bigrams \n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "from os import path\n",
    "from pandas.tseries.resample import TimeGrouper\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from scipy.misc import imread\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('mac_morpho')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "print 'OK!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.set_palette(\"deep\", desat=.6)\n",
    "# sns.set_context(rc={\"figure.figsize\": (8, 4)})\n",
    "# style.use('ggplot')\n",
    "# rcParams['axes.labelsize'] = 9\n",
    "# rcParams['xtick.labelsize'] = 9\n",
    "# rcParams['ytick.labelsize'] = 9\n",
    "# rcParams['legend.fontsize'] = 7\n",
    "# rcParams['font.serif'] = ['Ubuntu']\n",
    "# rcParams['font.size'] = 20\n",
    "# rcParams['text.usetex'] = False\n",
    "# rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "print 'OK!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_data_path = 'data/small-data.json'\n",
    "\n",
    "tweets_data = []\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "for line in tweets_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print len(tweets_data)\n",
    "print tweets_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mineração estável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame()\n",
    "\n",
    "tweets['text'] = map(lambda tweet: tweet['text'], tweets_data)\n",
    "tweets['lang'] = map(lambda tweet: tweet['lang'], tweets_data)\n",
    "tweets['country'] = map(lambda tweet: tweet['place']['country']\n",
    "                        if tweet['place'] != None else None, tweets_data)\n",
    "\n",
    "tweets_by_lang = tweets['lang'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.set_xlabel('Línguas'.decode('utf-8'), fontsize=20)\n",
    "ax.set_ylabel('Número de tweets'.decode('utf-8') , fontsize=20)\n",
    "ax.set_title('Top 4 Línguas'.decode('utf-8'), fontsize=20, fontweight='bold')\n",
    "tweets_by_lang[:4].plot(ax=ax, kind='bar', color='mediumspringgreen')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_by_country = tweets['country'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.set_xlabel('Países'.decode('utf-8'), fontsize=20)\n",
    "ax.set_ylabel('Número de tweets'.decode('utf-8') , fontsize=20)\n",
    "ax.set_title('Top 5 Países'.decode('utf-8'), fontsize=20, fontweight='bold')\n",
    "tweets_by_country[:5].plot(ax=ax, kind='bar', color='lightskyblue')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "    if match:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['NaoVaiTerGolpe'] = tweets['text'].apply(lambda tweet: word_in_text('NaoVaiTerGolpe', tweet))\n",
    "tweets['TchauQuerida'] = tweets['text'].apply(lambda tweet: word_in_text('TchauQuerida', tweet))\n",
    "tweets['ForaDilma'] = tweets['text'].apply(lambda tweet: word_in_text('ForaDilma', tweet))\n",
    "tweets['BrasilContraOGolpe'] = tweets['text'].apply(lambda tweet: word_in_text('BrasilContraOGolpe', tweet))\n",
    "tweets['ForaCunha'] = tweets['text'].apply(lambda tweet: word_in_text('ForaCunha', tweet))\n",
    "\n",
    "hashtags = ['ForaDilma', 'NaoVaiTerGolpe', 'TchauQuerida', 'BrasilContraOGolpe', 'ForaCunha']\n",
    "tweets_by_hashtags = [tweets['ForaDilma'].value_counts()[True],\n",
    "                      tweets['NaoVaiTerGolpe'].value_counts()[True],\n",
    "                      tweets['TchauQuerida'].value_counts()[True],\n",
    "                      tweets['BrasilContraOGolpe'].value_counts()[True],\n",
    "                      tweets['ForaCunha'].value_counts()[True]]\n",
    "\n",
    "plt.subplots(figsize=(10,10))\n",
    "colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'peachpuff']\n",
    "explode = (0.03, 0.03, 0.03, 0.03, 0.03)\n",
    "plt.pie(tweets_by_hashtags, explode=explode, labels=hashtags, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.legend(tweets_by_hashtags, loc=(.95,.6), title='Número de Tweets:'.decode('utf-8'), fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['nao'] = tweets['text'].apply(lambda tweet: word_in_text(' nao ', tweet))\n",
    "tweets['sim'] = tweets['text'].apply(lambda tweet: word_in_text(' sim ', tweet))\n",
    "\n",
    "tweets['ImpeachmentDay'] = tweets['text'].apply(lambda tweet: word_in_text(' sim ', tweet) \n",
    "                                          or word_in_text(' nao ', tweet))\n",
    "\n",
    "hashtags = ['ForaDilma', 'NaoVaiTerGolpe']\n",
    "tweets_by_hashtags = [tweets[tweets['ImpeachmentDay'] == True]['ForaDilma'].value_counts()[True], \n",
    "                      tweets[tweets['ImpeachmentDay'] == True]['NaoVaiTerGolpe'].value_counts()[True]]\n",
    "\n",
    "\n",
    "ind = np.arange(2)\n",
    "width = 0.5\n",
    "width2 = 0.3\n",
    "x_pos = list(range(len(hashtags)))\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "ax.bar(ind + width2, tweets_by_hashtags, width, color='yellowgreen')\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.set_ylabel('Número de tweets'.decode('utf-8'), fontsize=20)\n",
    "ax.set_title('Ranking: ForaDilma vs. NaoVaiTerGolpe (Votação SIM x NÃO)'.decode('utf-8'),\n",
    "             fontsize=15, fontweight='bold')\n",
    "ax.set_xticks([p + 1.1 * width for p in x_pos])\n",
    "ax.set_xticklabels(hashtags)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print tweets_by_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_link(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return ''\n",
    "\n",
    "tweets['link'] = tweets['text'].apply(lambda tweet: extract_link(tweet))\n",
    "\n",
    "tweets_relevant = tweets[tweets['ImpeachmentDay'] == True]\n",
    "tweets_relevant_with_link = tweets_relevant[tweets_relevant['link'] != '']\n",
    "\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['TchauQuerida'] == True]['link']\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['ForaDilma'] == True]['link']\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['ForaCunha'] == True]['link']\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['NaoVaiTerGolpe'] == True]['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['moro'] = tweets['text'].apply(lambda tweet: word_in_text('moro', tweet))\n",
    "tweets['cunha'] = tweets['text'].apply(lambda tweet: word_in_text('cunha', tweet))\n",
    "tweets['bolsonaro'] = tweets['text'].apply(lambda tweet: word_in_text('bolsonaro', tweet))\n",
    "tweets['lula'] = tweets['text'].apply(lambda tweet: word_in_text('lula', tweet))\n",
    "tweets['temer'] = tweets['text'].apply(lambda tweet: word_in_text('temer', tweet))\n",
    "tweets['feliciano'] = tweets['text'].apply(lambda tweet: word_in_text('feliciano', tweet))\n",
    "\n",
    "hashtags = ['Sérgio Moro'.decode('utf-8'), 'Eduardo Cunha', 'Jair Bolsonaro', 'Lula', 'Michel Temer', 'Marcos Feliciano']\n",
    "tweets_by_hashtags = [tweets['moro'].value_counts()[True],\n",
    "                      tweets['cunha'].value_counts()[True],\n",
    "                      tweets['bolsonaro'].value_counts()[True],\n",
    "                      tweets['lula'].value_counts()[True],\n",
    "                      tweets['feliciano'].value_counts()[True],\n",
    "                      tweets['temer'].value_counts()[True]]\n",
    "\n",
    "plt.subplots(figsize=(10,10))\n",
    "colors = ['gold', 'yellowgreen', 'lightskyblue', 'lightcoral', 'peachpuff', 'mediumturquoise']\n",
    "explode = (0.03, 0.03, 0.03, 0.05, 0.03, 0.03)\n",
    "plt.pie(tweets_by_hashtags, explode=explode, labels=hashtags, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "plt.rcParams['font.size'] = 15\n",
    "# plt.legend(tweets_by_hashtags, loc='best')\n",
    "plt.legend(tweets_by_hashtags, loc=(-.22,.6), title='Número de Tweets:'.decode('utf-8'), fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['created_at'] = map(lambda tweet: time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(tweet['created_at'],'%a %b %d %H:%M:%S +0000 %Y')), tweets_data)\n",
    "tweets['user'] = map(lambda tweet: tweet['user']['screen_name'], tweets_data)\n",
    "tweets['user_followers_count'] = map(lambda tweet: tweet['user']['followers_count'], tweets_data)\n",
    "tweets['retweet_count'] = map(lambda tweet: tweet['retweet_count'], tweets_data)\n",
    "tweets['favorite_count'] = map(lambda tweet: tweet['favorite_count'], tweets_data)\n",
    "\n",
    "tweets['text'] = map(lambda tweet: tweet['text'].encode('utf-8'), tweets_data)\n",
    "tweets['lang'] = map(lambda tweet: tweet['lang'], tweets_data)\n",
    "tweets['Location'] = map(lambda tweet: tweet['place']['country'] if tweet['place'] != None else None, tweets_data)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_original_tweets = [element for element in tweets['text'].values if not element.startswith('RT')]\n",
    "print list_of_original_tweets[0]\n",
    "\n",
    "print \"Numero de Tweets originais : \" + str(len(list_of_original_tweets))\n",
    "\n",
    "list_of_retweets = [element for element in tweets['text'].values if element.startswith('RT')]\n",
    "print \"Numero de Retweets : \" + str(len(list_of_retweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_tweets_per_category(tweets['user'], \n",
    "                             \"#ImpeachmentDay usuarios ativos\", \n",
    "                             \"Usuarios\", \n",
    "                             \"Numero de Tweets\", 20,\n",
    "                             \"ImpeachmentDay_users.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_distribution(category, title, x_title, y_title, output_filename=\"plot.png\"):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.tick_params(axis='x')\n",
    "        ax.tick_params(axis='y')\n",
    "        ax.set_xlabel(x_title)\n",
    "        ax.set_ylabel(y_title)\n",
    "        ax.set_title(title)\n",
    "        sns.distplot(category.values, rug=True, hist=True);\n",
    "        fig.savefig(output_filename)\n",
    "\n",
    "\n",
    "plot_distribution(tweets['retweet_count'], \n",
    "                      \"#ImpeachmentDay distribuicao de Retweets\", \"\", \"\",\n",
    "                      \"retweets_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweets['created_at'].value_counts(), columns=['number_tweets'])\n",
    "df['date'] = df.index\n",
    "df.head()\n",
    "\n",
    "days = [item.split(\" \")[0] for item in df['date'].values]\n",
    "df['days'] = days\n",
    "grouped_tweets = df[['days', 'number_tweets']].groupby('days')\n",
    "tweet_growth = grouped_tweets.sum()\n",
    "tweet_growth['days']= tweet_growth.index\n",
    "\n",
    "tweet_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "x_pos = np.arange(len(tweet_growth['days'].values))\n",
    "ax.bar(x_pos, tweet_growth['number_tweets'].values, align='center')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_title('#ImpeachmentDay hashtag growth')\n",
    "ax.set_ylabel(\"number tweets\")\n",
    "ax.set_xticklabels(tweet_growth['days'].values)\n",
    "fig.savefig('ImpeachmentDay.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \" \".join(tweets['text'].values.astype(str))\n",
    "\n",
    "no_urls_no_tags = \" \".join([word for word in text.split()\n",
    "                            if 'http' not in word\n",
    "                                and not word.startswith('@')\n",
    "                                and word != 'RT'\n",
    "                            ])\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=2000,\n",
    "                      stopwords=STOPWORDS, width=1800, height=1400).generate(no_urls_no_tags)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \" \".join(tweets['text'].values.astype(str))\n",
    "\n",
    "no_urls_no_tags = \" \".join([word for word in text.split()\n",
    "                            if 'http' not in word\n",
    "                                and not word.startswith('@')\n",
    "                                and word != 'RT'\n",
    "                            ])\n",
    "\n",
    "tweet_coloring = imread(path.join(\"dilma2.png\"))\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000, mask=tweet_coloring,\n",
    "               stopwords=STOPWORDS, max_font_size=40, random_state=42)\n",
    "\n",
    "wc.generate(no_urls_no_tags)\n",
    "\n",
    "image_colors = ImageColorGenerator(tweet_coloring)\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "plt.savefig('mozsprint.png', dpi=300)\n",
    "plt.imshow(wc.recolor(color_func=image_colors))\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "plt.imshow(tweet_coloring, cmap=plt.cm.gray)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* * *\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_json(\"data/small-data-fixed.json\")\n",
    "print 'OK!'\n",
    "type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coordinate = []\n",
    "for col in tweets['coordinates'][~tweets['coordinates'].isnull()]:\n",
    "    coord = col['coordinates'][::-1]\n",
    "    coordinate.append(coord)\n",
    "    \n",
    "print coordinate[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord_text = []\n",
    "for col in tweets['text'][~tweets['coordinates'].isnull()]:\n",
    "    coord = col.encode('utf-8')\n",
    "    coord_text.append(coord)\n",
    "    \n",
    "print coord_text[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets.set_index('coordinates', drop=False, inplace=True)\n",
    "tweets['text'][~tweets['coordinates'].isnull()].head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords = tweets['coordinates']\n",
    "coords = coords[~coords.isnull()]\n",
    "coords = coords.apply(lambda d: d['coordinates'][::-1])\n",
    "coords.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = folium.Map([-14,-53.25], zoom_start=4)\n",
    "\n",
    "for x, text in enumerate(coord_text):\n",
    "    folium.Marker(coordinate[x], popup=str(coordinate[x])).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets.text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_json(\"data/small-data-fixed.json\")\n",
    "print 'OK!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['created_at'] = pd.to_datetime(pd.Series(tweets['created_at']))\n",
    "\n",
    "tweets.set_index('created_at', drop=False, inplace=True)\n",
    "\n",
    "tweets.index = tweets.index.tz_localize('GMT')\n",
    "tweets.index = tweets.index - DateOffset(hours = 3)\n",
    "tweets.index\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets30s = tweets['created_at'].resample('1h', how='count')\n",
    "tweets30s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg = tweets30s.mean()\n",
    "\n",
    "vincent.core.initialize_notebook()\n",
    "area = vincent.Area(tweets30s)\n",
    "area.colors(brew='Spectral')\n",
    "area.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
