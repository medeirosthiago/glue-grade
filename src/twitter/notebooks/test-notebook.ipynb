{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/thiago/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package mac_morpho to\n",
      "[nltk_data]     /Users/thiago/nltk_data...\n",
      "[nltk_data]   Package mac_morpho is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/thiago/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import folium\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import operator \n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import pytz\n",
    "import random\n",
    "import re\n",
    "import seaborn as sns\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import vincent\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from matplotlib import dates\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from mpltools import style\n",
    "from nltk import FreqDist\n",
    "from nltk import bigrams \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from os import path\n",
    "from pandas.tseries.resample import TimeGrouper\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from scipy.misc import imread\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('mac_morpho')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set_context(rc={\"figure.figsize\": (8, 4)})\n",
    "style.use('ggplot')\n",
    "rcParams['axes.labelsize'] = 9\n",
    "rcParams['xtick.labelsize'] = 9\n",
    "rcParams['ytick.labelsize'] = 9\n",
    "rcParams['legend.fontsize'] = 7\n",
    "# rcParams['font.serif'] = ['Computer Modern Roman']\n",
    "rcParams['font.serif'] = ['Ubuntu']\n",
    "rcParams['text.usetex'] = False\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "# pd.set_option('display.max_colwidth', 200)\n",
    "# pd.options.display.mpl_style = 'default'\n",
    "# matplotlib.style.use('ggplot')\n",
    "# sns.set_context('talk')\n",
    "# sns.set_style('whitegrid')\n",
    "\n",
    "print 'OK!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "### Testando *folium* e *data frames*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_json(\"data/small-data-fixed.json\")\n",
    "print 'OK!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coords = tweets['coordinates']\n",
    "coords = coords[~coords.isnull()]\n",
    "coords.apply(lambda d: d['coordinates'])\n",
    "coords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = folium.Map([-14,-53.25], zoom_start=4)\n",
    "\n",
    "folium.Marker([-30.033, -51.2],\n",
    "                    popup='Testando cidade').add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['text'] = map(lambda tweet: df['text'].encode('utf-8'), tweets_data)\n",
    "tweets['user'] = map(lambda tweet: df['user']['screen_name'], tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "tweets['NaoVaiTerGolpe'] = tweets['text'].apply(lambda tweet: word_in_text('NaoVaiTerGolpe', tweet))\n",
    "tweets['TchauQuerida'] = tweets['text'].apply(lambda tweet: word_in_text('TchauQuerida', tweet))\n",
    "tweets['ForaDilma'] = tweets['text'].apply(lambda tweet: word_in_text('ForaDilma', tweet))\n",
    "tweets['BrasilContraOGolpe'] = tweets['text'].apply(lambda tweet: word_in_text('BrasilContraOGolpe', tweet))\n",
    "tweets['ForaCunha'] = tweets['text'].apply(lambda tweet: word_in_text('ForaCunha', tweet))\n",
    "\n",
    "tweets['user'] = map(lambda tweet: tweet['user']['screen_name'], tweets_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * \n",
    "\n",
    "### Funções de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datetimeify(df):\n",
    "    df['created_at'] = pd.DatetimeIndex(df.created_at)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment(df):\n",
    "    text = df.dropna(subset=['text']).text\n",
    "    sentiment = text.apply(lambda text: TextBlob(text).sentiment)\n",
    "    df['polarity'] = sentiment.apply(lambda sentiment: sentiment.polarity)\n",
    "    df['subjectivity'] = sentiment.apply(lambda sentiment: sentiment.subjectivity)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def influence(df):\n",
    "    internal = np.sqrt(df.user_followers_count.apply(lambda x: x + 1))\n",
    "    external = np.sqrt(df.retweet_count.apply(lambda x: x + 1))\n",
    "    df['influence'] = internal * external\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def influenced_polarity(df):\n",
    "    df['influenced_polarity'] = df.polarity * df['influence']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def georeference(df):\n",
    "    def place_to_coordinate(place_str, kind):\n",
    "        if pd.isnull(place_str):\n",
    "            return float('nan')\n",
    "        number_matcher = r'(-?\\d+\\.\\d+)[,\\]]'\n",
    "        coordinates = re.findall(number_matcher, place_str)\n",
    "        coordinate = tuple(float(n) for n in coordinates[:2])\n",
    "\n",
    "        if kind == 'longitude':\n",
    "            return coordinate[0]\n",
    "        elif kind == 'latitude':\n",
    "            return coordinate[1]\n",
    "    df['latitude'] = df.place.apply(place_to_coordinate, kind='latitude')\n",
    "    df['longitude'] = df.place.apply(place_to_coordinate, kind='longitude')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    return (df.pipe(datetimeify))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    cleaned = df.pipe(set_hashtags)\n",
    "    copy = cleaned.copy()\n",
    "    return preprocess(copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_df(input_filename):\n",
    "    raw_df = pd.read_json(input_filename)\n",
    "    return preprocess(raw_df)\n",
    "\n",
    "print 'OK'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "### Horários de Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = load_df('data/small-data-fixed.json')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tweets = pd.read_json('data/small-data-fixed.json')\n",
    "tweets['created_at'] = pd.to_datetime(pd.Series(tweets['created_at']))\n",
    "\n",
    "tweets.set_index('created_at', drop=False, inplace=True)\n",
    "\n",
    "tweets.info()\n",
    "tweets.index = tweets.index.tz_localize('GMT')\n",
    "tweets.index = tweets.index - DateOffset(hours = 3)\n",
    "tweets.index\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets30s = tweets['created_at'].resample('1s', how='count')\n",
    "tweets30s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg = tweets30s.mean()\n",
    "\n",
    "vincent.core.initialize_notebook()\n",
    "area = vincent.Area(tweets30s)\n",
    "area.colors(brew='Spectral')\n",
    "area.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "### Testes sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=True):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    " \n",
    "tweet = \"RT @medeirosthiiago: testando exemplo TCC! :D http://example.com #ImpeachmentDay\"\n",
    "print(preprocess(tweet))\n",
    "# ['RT', '@marcobonzanini', ':', 'just', 'an', 'example', '!', ':D', 'http://example.com', '#NLP']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
