{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/thiago/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package mac_morpho to\n",
      "[nltk_data]     /Users/thiago/nltk_data...\n",
      "[nltk_data]   Package mac_morpho is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/thiago/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import folium\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import operator \n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import random\n",
    "import re\n",
    "import seaborn as sns\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import vincent\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from matplotlib import dates\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from mpltools import style\n",
    "from nltk import FreqDist\n",
    "from nltk import bigrams \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from os import path\n",
    "from pandas.tseries.resample import TimeGrouper\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from scipy.misc import imread\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('mac_morpho')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set_context(rc={\"figure.figsize\": (8, 4)})\n",
    "style.use('ggplot')\n",
    "rcParams['axes.labelsize'] = 9\n",
    "rcParams['xtick.labelsize'] = 9\n",
    "rcParams['ytick.labelsize'] = 9\n",
    "rcParams['legend.fontsize'] = 7\n",
    "# rcParams['font.serif'] = ['Computer Modern Roman']\n",
    "rcParams['font.serif'] = ['Ubuntu']\n",
    "rcParams['text.usetex'] = False\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "# pd.set_option('display.max_colwidth', 200)\n",
    "# pd.options.display.mpl_style = 'default'\n",
    "# matplotlib.style.use('ggplot')\n",
    "# sns.set_context('talk')\n",
    "# sns.set_style('whitegrid')\n",
    "\n",
    "print 'OK!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "### Testando *folium* e *data frames*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 358293 entries, 0 to 358292\n",
      "Data columns (total 31 columns):\n",
      "contributors                 0 non-null float64\n",
      "coordinates                  470 non-null object\n",
      "created_at                   358293 non-null datetime64[ns]\n",
      "entities                     358293 non-null object\n",
      "extended_entities            164504 non-null object\n",
      "favorite_count               358293 non-null int64\n",
      "favorited                    358293 non-null bool\n",
      "filter_level                 358293 non-null object\n",
      "geo                          470 non-null object\n",
      "id                           358293 non-null int64\n",
      "id_str                       358293 non-null int64\n",
      "in_reply_to_screen_name      4820 non-null object\n",
      "in_reply_to_status_id        3303 non-null float64\n",
      "in_reply_to_status_id_str    3303 non-null float64\n",
      "in_reply_to_user_id          4820 non-null float64\n",
      "in_reply_to_user_id_str      4820 non-null float64\n",
      "is_quote_status              358293 non-null bool\n",
      "lang                         358293 non-null object\n",
      "place                        7803 non-null object\n",
      "possibly_sensitive           197101 non-null float64\n",
      "quoted_status                18300 non-null object\n",
      "quoted_status_id             18300 non-null float64\n",
      "quoted_status_id_str         18300 non-null float64\n",
      "retweet_count                358293 non-null int64\n",
      "retweeted                    358293 non-null bool\n",
      "retweeted_status             258109 non-null object\n",
      "source                       358293 non-null object\n",
      "text                         358293 non-null object\n",
      "timestamp_ms                 358293 non-null datetime64[ns]\n",
      "truncated                    358293 non-null bool\n",
      "user                         358293 non-null object\n",
      "dtypes: bool(4), datetime64[ns](2), float64(8), int64(4), object(13)\n",
      "memory usage: 77.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"data-docker/dilma-fixed.json\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  coordinates\n",
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['coordinates']]\n",
    "# df.columns = ['Texto', 'Usuário'.decode('utf-8'), 'Criação'.decode('utf-8')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * \n",
    "\n",
    "### Funções de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datetimeify(df):\n",
    "    df['created_at'] = pd.DatetimeIndex(df.created_at)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment(df):\n",
    "    text = df.dropna(subset=['text']).text\n",
    "    sentiment = text.apply(lambda text: TextBlob(text).sentiment)\n",
    "    df['polarity'] = sentiment.apply(lambda sentiment: sentiment.polarity)\n",
    "    df['subjectivity'] = sentiment.apply(lambda sentiment: sentiment.subjectivity)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def influence(df):\n",
    "    internal = np.sqrt(df.user_followers_count.apply(lambda x: x + 1))\n",
    "    external = np.sqrt(df.retweet_count.apply(lambda x: x + 1))\n",
    "    df['influence'] = internal * external\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def influenced_polarity(df):\n",
    "    df['influenced_polarity'] = df.polarity * df['influence']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def georeference(df):\n",
    "    def place_to_coordinate(place_str, kind):\n",
    "        if pd.isnull(place_str):\n",
    "            return float('nan')\n",
    "        number_matcher = r'(-?\\d+\\.\\d+)[,\\]]'\n",
    "        coordinates = re.findall(number_matcher, place_str)\n",
    "        coordinate = tuple(float(n) for n in coordinates[:2])\n",
    "\n",
    "        if kind == 'longitude':\n",
    "            return coordinate[0]\n",
    "        elif kind == 'latitude':\n",
    "            return coordinate[1]\n",
    "    df['latitude'] = df.place.apply(place_to_coordinate, kind='latitude')\n",
    "    df['longitude'] = df.place.apply(place_to_coordinate, kind='longitude')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    return (df.pipe(datetimeify))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    cleaned = df.pipe(set_hashtags)\n",
    "    copy = cleaned.copy()\n",
    "    return preprocess(copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_df(input_filename):\n",
    "    raw_df = pd.read_json(input_filename)\n",
    "    return preprocess(raw_df)\n",
    "\n",
    "print 'OK'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "### Horários de Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = load_df('data-docker/peda.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_json('data-docker/peda.json')\n",
    "tweets['created_at'] = pd.to_datetime(pd.Series(tweets['created_at']))\n",
    "\n",
    "tweets.set_index('created_at', drop=False, inplace=True)\n",
    "\n",
    "tweets.info()\n",
    "tweets.index = tweets.index.tz_localize('GMT')\n",
    "tweets.index = tweets.index - DateOffset(hours = 3)\n",
    "tweets.index\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets30s = tweets['created_at'].resample('1s', how='count')\n",
    "tweets30s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg = tweets30s.mean()\n",
    "\n",
    "vincent.core.initialize_notebook()\n",
    "area = vincent.Area(tweets30s)\n",
    "area.colors(brew='Spectral')\n",
    "area.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "### Testes sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=True):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    " \n",
    "tweet = \"RT @medeirosthiiago: testando exemplo TCC! :D http://example.com #ImpeachmentDay\"\n",
    "print(preprocess(tweet))\n",
    "# ['RT', '@marcobonzanini', ':', 'just', 'an', 'example', '!', ':D', 'http://example.com', '#NLP']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
