{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Mineração de *Tweets*\n",
    "Dados coletados durante o domingo (17/04/2015) de votação do Congresso para a continuação do processo de Impeachment da senhora Presidente Dilma Rousseff.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "print 'OK!'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import rcParams\n",
    "from mpltools import style\n",
    "from matplotlib import dates\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import random\n",
    "\n",
    "print 'OK!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Seaborn plots\n",
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set_context(rc={\"figure.figsize\": (8, 4)})\n",
    "# for R lovers :)\n",
    "style.use('ggplot')\n",
    "rcParams['axes.labelsize'] = 9\n",
    "rcParams['xtick.labelsize'] = 9\n",
    "rcParams['ytick.labelsize'] = 9\n",
    "rcParams['legend.fontsize'] = 7\n",
    "# rcParams['font.family'] = 'serif'\n",
    "rcParams['font.serif'] = ['Computer Modern Roman']\n",
    "rcParams['text.usetex'] = False\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "print 'OK!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "{u'contributors': None, u'truncated': False, u'text': u'RT @odialetos: QUINTA \\xc9 FERIADO #ImpeachmentDay https://t.co/zaF0CLCZEU', u'is_quote_status': False, u'in_reply_to_status_id': None, u'id': 721892546079825921, u'favorite_count': 0, u'source': u'<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', u'retweeted': False, u'coordinates': None, u'timestamp_ms': u'1460947569757', u'entities': {u'user_mentions': [{u'id': 252569242, u'indices': [3, 13], u'id_str': u'252569242', u'screen_name': u'odialetos', u'name': u'maconha'}], u'symbols': [], u'hashtags': [{u'indices': [32, 47], u'text': u'ImpeachmentDay'}], u'urls': [], u'media': [{u'source_user_id': 252569242, u'source_status_id_str': u'721849070042640384', u'expanded_url': u'http://twitter.com/odialetos/status/721849070042640384/photo/1', u'display_url': u'pic.twitter.com/zaF0CLCZEU', u'url': u'https://t.co/zaF0CLCZEU', u'media_url_https': u'https://pbs.twimg.com/media/CgSF4KrW4AAuMQu.jpg', u'source_user_id_str': u'252569242', u'source_status_id': 721849070042640384, u'id_str': u'721849040271499264', u'sizes': {u'small': {u'h': 145, u'resize': u'fit', u'w': 340}, u'large': {u'h': 438, u'resize': u'fit', u'w': 1024}, u'medium': {u'h': 257, u'resize': u'fit', u'w': 600}, u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}}, u'indices': [48, 71], u'type': u'photo', u'id': 721849040271499264, u'media_url': u'http://pbs.twimg.com/media/CgSF4KrW4AAuMQu.jpg'}]}, u'in_reply_to_screen_name': None, u'id_str': u'721892546079825921', u'retweet_count': 0, u'in_reply_to_user_id': None, u'favorited': False, u'retweeted_status': {u'contributors': None, u'truncated': False, u'text': u'QUINTA \\xc9 FERIADO #ImpeachmentDay https://t.co/zaF0CLCZEU', u'is_quote_status': False, u'in_reply_to_status_id': None, u'id': 721849070042640384, u'favorite_count': 196, u'source': u'<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', u'retweeted': False, u'coordinates': None, u'entities': {u'user_mentions': [], u'symbols': [], u'hashtags': [{u'indices': [17, 32], u'text': u'ImpeachmentDay'}], u'urls': [], u'media': [{u'expanded_url': u'http://twitter.com/odialetos/status/721849070042640384/photo/1', u'display_url': u'pic.twitter.com/zaF0CLCZEU', u'url': u'https://t.co/zaF0CLCZEU', u'media_url_https': u'https://pbs.twimg.com/media/CgSF4KrW4AAuMQu.jpg', u'id_str': u'721849040271499264', u'sizes': {u'small': {u'h': 145, u'resize': u'fit', u'w': 340}, u'large': {u'h': 438, u'resize': u'fit', u'w': 1024}, u'medium': {u'h': 257, u'resize': u'fit', u'w': 600}, u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}}, u'indices': [33, 56], u'type': u'photo', u'id': 721849040271499264, u'media_url': u'http://pbs.twimg.com/media/CgSF4KrW4AAuMQu.jpg'}]}, u'in_reply_to_screen_name': None, u'id_str': u'721849070042640384', u'retweet_count': 476, u'in_reply_to_user_id': None, u'favorited': False, u'user': {u'follow_request_sent': None, u'profile_use_background_image': False, u'default_profile_image': False, u'id': 252569242, u'verified': False, u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/714612401153433600/8mCHt6g-_normal.jpg', u'profile_sidebar_fill_color': u'EFEFEF', u'profile_text_color': u'333333', u'followers_count': 74616, u'profile_sidebar_border_color': u'FFFFFF', u'id_str': u'252569242', u'profile_background_color': u'F7F7F7', u'listed_count': 68, u'profile_background_image_url_https': u'https://pbs.twimg.com/profile_background_images/459039780303409153/5WOm0rkx.jpeg', u'utc_offset': -7200, u'statuses_count': 53092, u'description': u'foda-se', u'friends_count': 14557, u'location': None, u'profile_link_color': u'ABB8C2', u'profile_image_url': u'http://pbs.twimg.com/profile_images/714612401153433600/8mCHt6g-_normal.jpg', u'following': None, u'geo_enabled': True, u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/252569242/1458528673', u'profile_background_image_url': u'http://pbs.twimg.com/profile_background_images/459039780303409153/5WOm0rkx.jpeg', u'name': u'maconha', u'lang': u'pt', u'profile_background_tile': False, u'favourites_count': 33, u'screen_name': u'odialetos', u'notifications': None, u'url': None, u'created_at': u'Tue Feb 15 13:21:40 +0000 2011', u'contributors_enabled': False, u'time_zone': u'Greenland', u'protected': False, u'default_profile': False, u'is_translator': False}, u'geo': None, u'in_reply_to_user_id_str': None, u'possibly_sensitive': False, u'lang': u'pt', u'created_at': u'Sun Apr 17 23:53:24 +0000 2016', u'filter_level': u'low', u'in_reply_to_status_id_str': None, u'place': None, u'extended_entities': {u'media': [{u'expanded_url': u'http://twitter.com/odialetos/status/721849070042640384/photo/1', u'display_url': u'pic.twitter.com/zaF0CLCZEU', u'url': u'https://t.co/zaF0CLCZEU', u'media_url_https': u'https://pbs.twimg.com/media/CgSF4KrW4AAuMQu.jpg', u'id_str': u'721849040271499264', u'sizes': {u'small': {u'h': 145, u'resize': u'fit', u'w': 340}, u'large': {u'h': 438, u'resize': u'fit', u'w': 1024}, u'medium': {u'h': 257, u'resize': u'fit', u'w': 600}, u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}}, u'indices': [33, 56], u'type': u'photo', u'id': 721849040271499264, u'media_url': u'http://pbs.twimg.com/media/CgSF4KrW4AAuMQu.jpg'}]}}, u'user': {u'follow_request_sent': None, u'profile_use_background_image': False, u'default_profile_image': False, u'id': 341310199, u'verified': False, u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/719594396623245317/1Hnn256M_normal.jpg', u'profile_sidebar_fill_color': u'F3F3F3', u'profile_text_color': u'990000', u'followers_count': 342, u'profile_sidebar_border_color': u'FFFFFF', u'id_str': u'341310199', u'profile_background_color': u'ACDED6', u'listed_count': 0, u'profile_background_image_url_https': u'https://pbs.twimg.com/profile_background_images/829884214/77bafa73e0f1b6312931d49f342950ab.jpeg', u'utc_offset': -10800, u'statuses_count': 8658, u'description': None, u'friends_count': 348, u'location': u'infelizmente n\\xe3o na coreia', u'profile_link_color': u'F58EA8', u'profile_image_url': u'http://pbs.twimg.com/profile_images/719594396623245317/1Hnn256M_normal.jpg', u'following': None, u'geo_enabled': False, u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/341310199/1460400043', u'profile_background_image_url': u'http://pbs.twimg.com/profile_background_images/829884214/77bafa73e0f1b6312931d49f342950ab.jpeg', u'name': u'\\u2606Jubba\\u2606', u'lang': u'pt', u'profile_background_tile': False, u'favourites_count': 14028, u'screen_name': u'fckchimchim', u'notifications': None, u'url': None, u'created_at': u'Sun Jul 24 04:52:19 +0000 2011', u'contributors_enabled': False, u'time_zone': u'Brasilia', u'protected': False, u'default_profile': False, u'is_translator': False}, u'geo': None, u'in_reply_to_user_id_str': None, u'possibly_sensitive': False, u'lang': u'pt', u'created_at': u'Mon Apr 18 02:46:09 +0000 2016', u'filter_level': u'low', u'in_reply_to_status_id_str': None, u'place': None, u'extended_entities': {u'media': [{u'source_user_id': 252569242, u'source_status_id_str': u'721849070042640384', u'expanded_url': u'http://twitter.com/odialetos/status/721849070042640384/photo/1', u'display_url': u'pic.twitter.com/zaF0CLCZEU', u'url': u'https://t.co/zaF0CLCZEU', u'media_url_https': u'https://pbs.twimg.com/media/CgSF4KrW4AAuMQu.jpg', u'source_user_id_str': u'252569242', u'source_status_id': 721849070042640384, u'id_str': u'721849040271499264', u'sizes': {u'small': {u'h': 145, u'resize': u'fit', u'w': 340}, u'large': {u'h': 438, u'resize': u'fit', u'w': 1024}, u'medium': {u'h': 257, u'resize': u'fit', u'w': 600}, u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}}, u'indices': [48, 71], u'type': u'photo', u'id': 721849040271499264, u'media_url': u'http://pbs.twimg.com/media/CgSF4KrW4AAuMQu.jpg'}]}}\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "tweets_data_path = 'data-docker/peda.json'\n",
    "\n",
    "tweets_data = []\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "for line in tweets_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print len(tweets_data)\n",
    "print tweets_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named cartopy",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f7214a872c80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcartopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_colwidth'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmpl_style\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named cartopy"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import cartopy\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.options.display.mpl_style = 'default'\n",
    "matplotlib.style.use('ggplot')\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrumar - Mineração de horários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from pandas.tseries.resample import TimeGrouper\n",
    "# from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "# tweets_time = pd.Series()\n",
    "\n",
    "# # tweets_time['created_at'] = map(lambda tweet: time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(tweet['created_at'],'%a %b %d %H:%M:%S +0000 %Y')), tweets_data)\n",
    "# tweets_time['created_at'] = pd.to_datetime(pd.Series(tweets_time['created_at']))\n",
    "# # tweets_time.se('created_at', drop=False, inplace=True)\n",
    "# # tweets_time.index = tweets_time.index.tzlocalize('GMT').tzconvert('EST')\n",
    "# # tweets_time.index = tweets_time.index - DateOffset(hours = 12)\n",
    "# # tweets_time.index\n",
    "\n",
    "# tweets_time.head()\n",
    "# # tweets_time.mean()\n",
    "# # print 'testou'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pytz\n",
    "# from pandas.tseries.resample import TimeGrouper\n",
    "# from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "# tz = pytz.timezone('Europe/Warsaw')\n",
    "# tweets.set_index('created_at', drop=False, inplace=True)\n",
    "# # tweets.index = tweets.index\n",
    "# # tweets.index = tweets.tz_localize('GMT').tz_convert('EST')\n",
    "# # tweets.index = tweets.index - DateOffset(hours = 12)\n",
    "\n",
    "\n",
    "# tweets_time = tweets['created_at']\n",
    "# tweets.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.resample import TimeGrouper\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "\n",
    "df = pd.DataFrame(tweets['created_at'].value_counts())\n",
    "df['hour'] = df.index\n",
    "\n",
    "hours = [item.split(\" \")[0] for item in df['hour'].values]\n",
    "df['hours'] = hours\n",
    "grouped_tweets = df[['hours']].groupby('hours')\n",
    "tweet_growth = grouped_tweets.sum()\n",
    "tweet_growth['hours']= tweet_growth.index\n",
    "\n",
    "tweet_growth\n",
    "# df.info()\n",
    "# df.tail()\n",
    "# df.mean()\n",
    "\n",
    "df.describe()\n",
    "\n",
    "import vincent\n",
    "vincent.core.initialize_notebook()\n",
    "area = vincent.Area(df)\n",
    "area.colors(brew='Spectral')\n",
    "area.display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* * *\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tweets = pd.DataFrame()\n",
    "\n",
    "tweets['created_at'] = map(lambda tweet: time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(tweet['created_at'],'%a %b %d %H:%M:%S +0000 %Y')), tweets_data)\n",
    "tweets['user'] = map(lambda tweet: tweet['user']['screen_name'], tweets_data)\n",
    "tweets['user_followers_count'] = map(lambda tweet: tweet['user']['followers_count'], tweets_data)\n",
    "tweets['retweet_count'] = map(lambda tweet: tweet['retweet_count'], tweets_data)\n",
    "tweets['favorite_count'] = map(lambda tweet: tweet['favorite_count'], tweets_data)\n",
    "\n",
    "tweets['text'] = map(lambda tweet: tweet['text'].encode('utf-8'), tweets_data)\n",
    "tweets['lang'] = map(lambda tweet: tweet['lang'], tweets_data)\n",
    "tweets['Location'] = map(lambda tweet: tweet['place']['country'] if tweet['place'] != None else None, tweets_data)\n",
    "\n",
    "\n",
    "tweets.info()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('mac_morpho')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "stop = stopwords.words('mac_morpho')\n",
    "text = tweets['text']\n",
    "\n",
    "\n",
    "tokens = []\n",
    "for txt in text.values:\n",
    "    tokens.extend([t.lower().strip(\":,.\") for t in txt.split()])\n",
    "\n",
    "\n",
    "\n",
    "filtered_tokens = [w for w in tokens if not w in stop]\n",
    "\n",
    "freqdist = nltk.FreqDist(filteredtokens)\n",
    "\n",
    "\n",
    "freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_dist.keys()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_dist.plot(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flyers.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* * *\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_original_tweets = [element for element in tweets['text'].values if not element.startswith('RT')]\n",
    "print list_of_original_tweets[0]\n",
    "\n",
    "print \"Number of Original Tweets : \" + str(len(list_of_original_tweets))\n",
    "\n",
    "list_of_retweets = [element for element in tweets['text'].values if element.startswith('RT')]\n",
    "print \"Number of Retweets : \" + str(len(list_of_retweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_tweets_per_category(category, title, x_title, y_title, top_n=5, output_filename=\"plot.png\"):\n",
    "    \"\"\"\n",
    "    :param category: Category plotted, can be tweets users, tweets language, tweets country etc ..\n",
    "    :param title: Title of the plot\n",
    "    :param x_title: List of the items in x\n",
    "    :param y_title: Title of the variable plotted\n",
    "    :return: a plot that we can save as pdf or png instead of displaying to the screen\n",
    "    \"\"\"\n",
    "    tweets_by_cat = category.value_counts()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.tick_params(axis='x')\n",
    "    ax.tick_params(axis='y')\n",
    "    ax.set_xlabel(x_title)\n",
    "    ax.set_ylabel(y_title)\n",
    "    ax.set_title(title)\n",
    "    tweets_by_cat[:top_n].plot(ax=ax, kind='bar')\n",
    "    fig.savefig(output_filename)\n",
    "    fig.show()\n",
    "\n",
    "plot_tweets_per_category(tweets['lang'], \"#ImpeachmentDay by Language\", \n",
    "                         \"Language\", \n",
    "                         \"Number of Tweets\", \n",
    "                         2000,\n",
    "                         \"mozsprint_per_language.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_tweets_per_category(tweets['Location'], \n",
    "                             \"#ImpeachmentDay by Location\", \n",
    "                             \"Location\", \n",
    "                             \"Number of Tweets\", 2000,\n",
    "                             \"ImpeachmentDay_per_location.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_tweets_per_category(tweets['user'], \n",
    "                             \"#ImpeachmentDay active users\", \n",
    "                             \"Users\", \n",
    "                             \"Number of Tweets\", 20,\n",
    "                             \"ImpeachmentDay_users.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_distribution(category, title, x_title, y_title, output_filename=\"plot.png\"):\n",
    "        \"\"\"\n",
    "        :param category: Category plotted, can be users, language, country etc ..\n",
    "        :param title: Title of the plot\n",
    "        :param x_title: List of the items in x\n",
    "        :param y_title: Title of the variable plotted\n",
    "        :return: a plot that we can save as pdf or png instead of displaying to the screen\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.tick_params(axis='x')\n",
    "        ax.tick_params(axis='y')\n",
    "        ax.set_xlabel(x_title)\n",
    "        ax.set_ylabel(y_title)\n",
    "        ax.set_title(title)\n",
    "        sns.distplot(category.values, rug=True, hist=True);\n",
    "        fig.savefig(output_filename)\n",
    "\n",
    "\n",
    "plot_distribution(tweets['retweet_count'], \n",
    "                      \"#ImpeachmentDay retweets distribution\", \"\", \"\",\n",
    "                      \"retweets_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweets['created_at'].value_counts(), columns=['number_tweets'])\n",
    "df['date'] = df.index\n",
    "df.head()\n",
    "\n",
    "days = [item.split(\" \")[0] for item in df['date'].values]\n",
    "df['days'] = days\n",
    "grouped_tweets = df[['days', 'number_tweets']].groupby('days')\n",
    "tweet_growth = grouped_tweets.sum()\n",
    "tweet_growth['days']= tweet_growth.index\n",
    "\n",
    "tweet_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "x_pos = np.arange(len(tweet_growth['days'].values))\n",
    "ax.bar(x_pos, tweet_growth['number_tweets'].values, align='center')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_title('#ImpeachmentDay hashtag growth')\n",
    "ax.set_ylabel(\"number tweets\")\n",
    "ax.set_xticklabels(tweet_growth['days'].values)\n",
    "fig.savefig('ImpeachmentDay.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \" \".join(tweets['text'].values.astype(str))\n",
    "\n",
    "no_urls_no_tags = \" \".join([word for word in text.split()\n",
    "                            if 'http' not in word\n",
    "                                and not word.startswith('@')\n",
    "                                and word != 'RT'\n",
    "                            ])\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=2000,\n",
    "                      stopwords=STOPWORDS, width=1800, height=1400).generate(no_urls_no_tags)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "text = \" \".join(tweets['text'].values.astype(str))\n",
    "\n",
    "no_urls_no_tags = \" \".join([word for word in text.split()\n",
    "                            if 'http' not in word\n",
    "                                and not word.startswith('@')\n",
    "                                and word != 'RT'\n",
    "                            ])\n",
    "\n",
    "tweet_coloring = imread(path.join(\"dilma2.png\"))\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000, mask=tweet_coloring,\n",
    "               stopwords=STOPWORDS, max_font_size=40, random_state=42)\n",
    "\n",
    "wc.generate(no_urls_no_tags)\n",
    "\n",
    "image_colors = ImageColorGenerator(tweet_coloring)\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "plt.savefig('mozsprint.png', dpi=300)\n",
    "plt.imshow(wc.recolor(color_func=image_colors))\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "plt.imshow(tweet_coloring, cmap=plt.cm.gray)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* * *\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dados minerados anteriormente - OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame()\n",
    "\n",
    "tweets['text'] = map(lambda tweet: tweet['text'], tweets_data)\n",
    "tweets['lang'] = map(lambda tweet: tweet['lang'], tweets_data)\n",
    "tweets['country'] = map(lambda tweet: tweet['place']['country']\n",
    "                        if tweet['place'] != None else None, tweets_data)\n",
    "\n",
    "tweets_by_lang = tweets['lang'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.set_xlabel('Línguas'.decode('utf-8'), fontsize=20)\n",
    "ax.set_ylabel('Número de tweets'.decode('utf-8') , fontsize=20)\n",
    "ax.set_title('Top 4 Línguas'.decode('utf-8'), fontsize=20, fontweight='bold')\n",
    "tweets_by_lang[:4].plot(ax=ax, kind='bar', color='mediumspringgreen')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_by_country = tweets['country'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.set_xlabel('Países'.decode('utf-8'), fontsize=20)\n",
    "ax.set_ylabel('Número de tweets'.decode('utf-8') , fontsize=20)\n",
    "ax.set_title('Top 5 Países'.decode('utf-8'), fontsize=20, fontweight='bold')\n",
    "tweets_by_country[:5].plot(ax=ax, kind='bar', color='lightskyblue')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "tweets['NaoVaiTerGolpe'] = tweets['text'].apply(lambda tweet: word_in_text('NaoVaiTerGolpe', tweet))\n",
    "tweets['TchauQuerida'] = tweets['text'].apply(lambda tweet: word_in_text('TchauQuerida', tweet))\n",
    "tweets['ForaDilma'] = tweets['text'].apply(lambda tweet: word_in_text('ForaDilma', tweet))\n",
    "# tweets['BrasilContraOGolpe'] = tweets['text'].apply(lambda tweet: word_in_text('BrasilContraOGolpe', tweet))\n",
    "# tweets['ForaCunha'] = tweets['text'].apply(lambda tweet: word_in_text('ForaCunha', tweet))\n",
    "\n",
    "# print tweets['FicaQuerida'].value_counts()[True]\n",
    "# print tweets['NaoVaiTerGolpe'].value_counts()[True]\n",
    "# print tweets['ForaPT'].value_counts()[True]\n",
    "\n",
    "# hashtags = ['ForaDilma', 'NaoVaiTerGolpe', 'TchauQuerida', 'BrasilContraOGolpe', 'ForaCunha']\n",
    "hashtags = ['ForaDilma', 'NaoVaiTerGolpe', 'TchauQuerida']\n",
    "tweets_by_hashtags = [tweets['ForaDilma'].value_counts()[True],\n",
    "                      tweets['NaoVaiTerGolpe'].value_counts()[True],\n",
    "                      tweets['TchauQuerida'].value_counts()[True]]\n",
    "#                       tweets['BrasilContraOGolpe'].value_counts()[True],\n",
    "#                       tweets['ForaCunha'].value_counts()[True]]\n",
    "\n",
    "plt.subplots(figsize=(9,9))\n",
    "colors = ['gold', 'yellowgreen', 'lightcoral']\n",
    "explode = (0.03, 0.03, 0.03)\n",
    "plt.pie(tweets_by_hashtags, explode=explode, labels=hashtags, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.legend(tweets_by_hashtags, loc=(1,.6))\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['nao'] = tweets['text'].apply(lambda tweet: word_in_text('nao', tweet))\n",
    "tweets['sim'] = tweets['text'].apply(lambda tweet: word_in_text('sim', tweet))\n",
    "\n",
    "tweets['ImpeachmentDay'] = tweets['text'].apply(lambda tweet: word_in_text('sim', tweet) \n",
    "                                          or word_in_text('nao', tweet))\n",
    "\n",
    "# print tweets['nao'].value_counts()[True]\n",
    "# print tweets['sim'].value_counts()[True]\n",
    "# print tweets['ImpeachmentDay'].value_counts()[True]\n",
    "\n",
    "# print tweets[tweets['ImpeachmentDay'] == True]['ForaDilma'].value_counts()[True]\n",
    "# print tweets[tweets['ImpeachmentDay'] == True]['NaoVaiTerGolpe'].value_counts()[True]\n",
    "\n",
    "hashtags = ['ForaDilma', 'NaoVaiTerGolpe']\n",
    "tweets_by_hashtags = [tweets[tweets['ImpeachmentDay'] == True]['ForaDilma'].value_counts()[True], \n",
    "                      tweets[tweets['ImpeachmentDay'] == True]['NaoVaiTerGolpe'].value_counts()[True]]\n",
    "\n",
    "x_pos = list(range(len(hashtags)))\n",
    "width = 0.7\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.bar(x_pos, tweets_by_hashtags, width, alpha=1, color='sienna')\n",
    "ax.set_ylabel('Número de tweets'.decode('utf-8'), fontsize=20)\n",
    "ax.set_title('Ranking: ForaDilma vs. NaoVaiTerGolpe (Votação SIM x NÃO)'.decode('utf-8'),\n",
    "             fontsize=15, fontweight='bold')\n",
    "ax.set_xticks([p + 0.4 * width for p in x_pos])\n",
    "ax.set_xticklabels(hashtags)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_link(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return ''\n",
    "\n",
    "tweets['link'] = tweets['text'].apply(lambda tweet: extract_link(tweet))\n",
    "\n",
    "tweets_relevant = tweets[tweets['ImpeachmentDay'] == True]\n",
    "tweets_relevant_with_link = tweets_relevant[tweets_relevant['link'] != '']\n",
    "\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['TchauQuerida'] == True]['link']\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['ForaDilma'] == True]['link']\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['ForaCunha'] == True]['link']\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['NaoVaiTerGolpe'] == True]['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['moro'] = tweets['text'].apply(lambda tweet: word_in_text('moro', tweet))\n",
    "tweets['cunha'] = tweets['text'].apply(lambda tweet: word_in_text('cunha', tweet))\n",
    "tweets['bolsonaro'] = tweets['text'].apply(lambda tweet: word_in_text('bolsonaro', tweet))\n",
    "tweets['lula'] = tweets['text'].apply(lambda tweet: word_in_text('lula', tweet))\n",
    "tweets['temer'] = tweets['text'].apply(lambda tweet: word_in_text('temer', tweet))\n",
    "tweets['feliciano'] = tweets['text'].apply(lambda tweet: word_in_text('feliciano', tweet))\n",
    "\n",
    "hashtags = ['Sérgio Moro'.decode('utf-8'), 'Eduardo Cunha', 'Jair Bolsonaro', 'Lula', 'Michel Temer', 'Marcos Feliciano']\n",
    "tweets_by_hashtags = [tweets['moro'].value_counts()[True],\n",
    "                      tweets['cunha'].value_counts()[True],\n",
    "                      tweets['bolsonaro'].value_counts()[True],\n",
    "                      tweets['lula'].value_counts()[True],\n",
    "                      tweets['feliciano'].value_counts()[True],\n",
    "                      tweets['temer'].value_counts()[True]]\n",
    "\n",
    "plt.subplots(figsize=(8,8))\n",
    "colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'peachpuff', 'mediumturquoise']\n",
    "explode = (0.03, 0.03, 0.03, 0.05, 0.03, 0.03)\n",
    "plt.pie(tweets_by_hashtags, explode=explode, labels=hashtags, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.legend(tweets_by_hashtags, loc='best')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ainda ajustando aqui - Funções de busca de *tweets*, salvar e carregar json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io, json\n",
    "\n",
    "def twitter_search(q, max_results=1000, **kw):\n",
    "    search_results = twitter_api.search.tweets(q=q, count=1000, **kw)\n",
    "    \n",
    "    statuses = search_results['statuses']\n",
    "    \n",
    "    max_results = min(10000, max_results)\n",
    "    \n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_resuts']\n",
    "        except KeyError, e:\n",
    "            break\n",
    "            \n",
    "        kwargs = dict([ kv.split('=')\n",
    "                        for kv in next_results[1:].split(\"&\") ])\n",
    "        \n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "        \n",
    "        if len(statuses) > max_results:\n",
    "            break\n",
    "            \n",
    "    return statuses\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "q = 'ForaInternetLimitada'\n",
    "results = twitter_search(twitter_api, q, max_results=1000)\n",
    "\n",
    "print json.dumps(results[0], indent=1)\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_json(filename, data):\n",
    "    with io.open('data/{0}.json'.format(filename),\n",
    "                 'w', encoding='utf-8') as f:\n",
    "            f.write(unicode(json.dumps(data, ensure_ascii=False)))\n",
    "    \n",
    "def load_json(filename):\n",
    "    with io.open('data/{0}.json'.format(filename),\n",
    "                  encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "\n",
    "q = 'ForaInternetLimitada'\n",
    "\n",
    "\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "results = twitter_search(twitter_api, q, max_results=1000)\n",
    "\n",
    "save_json(q, results)\n",
    "results = load_json(q)\n",
    "\n",
    "# print json.dumps(results, indent=1)\n",
    "\n",
    "# print json.dumps(br_trends, indent=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
