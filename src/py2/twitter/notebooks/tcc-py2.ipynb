{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing Docker on Cloud! ;)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thiago/Envs/tcc-py2/lib/python2.7/site-packages/mpltools/style/__init__.py:42: FutureWarning: \n",
      "\n",
      "    The style-sheet functionality in mpltools has been integrated into\n",
      "    Matplotlib >= 1.4. This module will be removed in a future release.\n",
      "\n",
      "    Note that style-sheets used by `matplotlib.style` use the standard\n",
      "    Matplotlib rc-file syntax instead of the INI format used by `mpltools`.\n",
      "    This mostly means un-quoting strings and changing '=' to ':'.\n",
      "\n",
      "\n",
      "  \"\"\", FutureWarning)\n",
      "/Users/thiago/Envs/tcc-py2/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# from tweepy import OAuthHandler\n",
    "# from tweepy import API\n",
    "# from tweepy import Cursor\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "print 'OK!'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import rcParams\n",
    "from mpltools import style\n",
    "from matplotlib import dates\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import scipy\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import random\n",
    "\n",
    "print 'OK!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Seaborn plots\n",
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set_context(rc={\"figure.figsize\": (8, 4)})\n",
    "# for R lovers :)\n",
    "style.use('ggplot')\n",
    "rcParams['axes.labelsize'] = 9\n",
    "rcParams['xtick.labelsize'] = 9\n",
    "rcParams['ytick.labelsize'] = 9\n",
    "rcParams['legend.fontsize'] = 7\n",
    "# rcParams['font.family'] = 'serif'\n",
    "rcParams['font.serif'] = ['Computer Modern Roman']\n",
    "rcParams['text.usetex'] = False\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "print 'OK!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358293\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "tweets_data_path = '../data/dilmahash.txt'\n",
    "\n",
    "tweets_data = []\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "for line in tweets_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print len(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 358293 entries, 0 to 358292\n",
      "Data columns (total 5 columns):\n",
      "created_at              358293 non-null object\n",
      "user                    358293 non-null object\n",
      "user_followers_count    358293 non-null int64\n",
      "retweet_count           358293 non-null int64\n",
      "favorite_count          358293 non-null int64\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 16.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>user</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-17 15:15:21</td>\n",
       "      <td>exxonre</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-17 15:15:21</td>\n",
       "      <td>DetritoFederal1</td>\n",
       "      <td>2428</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-17 15:15:21</td>\n",
       "      <td>Souzaa_mih1</td>\n",
       "      <td>433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-17 15:15:21</td>\n",
       "      <td>italo_filho</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-17 15:15:22</td>\n",
       "      <td>camzminhao</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at             user  user_followers_count  retweet_count  \\\n",
       "0  2016-04-17 15:15:21          exxonre                    28              0   \n",
       "1  2016-04-17 15:15:21  DetritoFederal1                  2428              0   \n",
       "2  2016-04-17 15:15:21      Souzaa_mih1                   433              0   \n",
       "3  2016-04-17 15:15:21      italo_filho                    42              0   \n",
       "4  2016-04-17 15:15:22       camzminhao                   443              0   \n",
       "\n",
       "   favorite_count  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "tweets = pd.DataFrame()\n",
    "\n",
    "tweets['created_at'] = map(lambda tweet: time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(tweet['created_at'],'%a %b %d %H:%M:%S +0000 %Y')), tweets_data)\n",
    "tweets['user'] = map(lambda tweet: tweet['user']['screen_name'], tweets_data)\n",
    "tweets['user_followers_count'] = map(lambda tweet: tweet['user']['followers_count'], tweets_data)\n",
    "tweets['retweet_count'] = map(lambda tweet: tweet['retweet_count'], tweets_data)\n",
    "tweets['favorite_count'] = map(lambda tweet: tweet['favorite_count'], tweets_data)\n",
    "\n",
    "print 'OK!'\n",
    "\n",
    "tweets.info()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>2016-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>2016-04-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hours\n",
       "hours                 \n",
       "2016-04-17  2016-04-17\n",
       "2016-04-18  2016-04-18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tweets['created_at'].value_counts())\n",
    "df['hour'] = df.index\n",
    "df.head()\n",
    "\n",
    "hours = [item.split(\" \")[0] for item in df['hour'].values]\n",
    "df['hours'] = hours\n",
    "grouped_tweets = df[['hours']].groupby('hours')\n",
    "tweet_growth = grouped_tweets.sum()\n",
    "tweet_growth['hours']= tweet_growth.index\n",
    "\n",
    "tweet_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame()\n",
    "\n",
    "tweets['text'] = map(lambda tweet: tweet['text'], tweets_data)\n",
    "tweets['lang'] = map(lambda tweet: tweet['lang'], tweets_data)\n",
    "tweets['country'] = map(lambda tweet: tweet['place']['country']\n",
    "                        if tweet['place'] != None else None, tweets_data)\n",
    "\n",
    "tweets_by_lang = tweets['lang'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.set_xlabel('Línguas'.decode('utf-8'), fontsize=20)\n",
    "ax.set_ylabel('Número de tweets'.decode('utf-8') , fontsize=20)\n",
    "ax.set_title('Top 4 Línguas'.decode('utf-8'), fontsize=20, fontweight='bold')\n",
    "tweets_by_lang[:4].plot(ax=ax, kind='bar', color='mediumspringgreen')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_by_country = tweets['country'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.set_xlabel('Países'.decode('utf-8'), fontsize=20)\n",
    "ax.set_ylabel('Número de tweets'.decode('utf-8') , fontsize=20)\n",
    "ax.set_title('Top 5 Países'.decode('utf-8'), fontsize=20, fontweight='bold')\n",
    "tweets_by_country[:5].plot(ax=ax, kind='bar', color='lightskyblue')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "tweets['NaoVaiTerGolpe'] = tweets['text'].apply(lambda tweet: word_in_text('NaoVaiTerGolpe', tweet))\n",
    "tweets['TchauQuerida'] = tweets['text'].apply(lambda tweet: word_in_text('TchauQuerida', tweet))\n",
    "tweets['ForaDilma'] = tweets['text'].apply(lambda tweet: word_in_text('ForaDilma', tweet))\n",
    "# tweets['BrasilContraOGolpe'] = tweets['text'].apply(lambda tweet: word_in_text('BrasilContraOGolpe', tweet))\n",
    "# tweets['ForaCunha'] = tweets['text'].apply(lambda tweet: word_in_text('ForaCunha', tweet))\n",
    "\n",
    "# print tweets['FicaQuerida'].value_counts()[True]\n",
    "# print tweets['NaoVaiTerGolpe'].value_counts()[True]\n",
    "# print tweets['ForaPT'].value_counts()[True]\n",
    "\n",
    "# hashtags = ['ForaDilma', 'NaoVaiTerGolpe', 'TchauQuerida', 'BrasilContraOGolpe', 'ForaCunha']\n",
    "hashtags = ['ForaDilma', 'NaoVaiTerGolpe', 'TchauQuerida']\n",
    "tweets_by_hashtags = [tweets['ForaDilma'].value_counts()[True],\n",
    "                      tweets['NaoVaiTerGolpe'].value_counts()[True],\n",
    "                      tweets['TchauQuerida'].value_counts()[True]]\n",
    "#                       tweets['BrasilContraOGolpe'].value_counts()[True],\n",
    "#                       tweets['ForaCunha'].value_counts()[True]]\n",
    "\n",
    "plt.subplots(figsize=(9,9))\n",
    "colors = ['gold', 'yellowgreen', 'lightcoral']\n",
    "explode = (0.03, 0.03, 0.03)\n",
    "plt.pie(tweets_by_hashtags, explode=explode, labels=hashtags, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.legend(tweets_by_hashtags, loc=(1,.6))\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['nao'] = tweets['text'].apply(lambda tweet: word_in_text('nao', tweet))\n",
    "tweets['sim'] = tweets['text'].apply(lambda tweet: word_in_text('sim', tweet))\n",
    "\n",
    "tweets['ImpeachmentDay'] = tweets['text'].apply(lambda tweet: word_in_text('sim', tweet) \n",
    "                                          or word_in_text('nao', tweet))\n",
    "\n",
    "# print tweets['nao'].value_counts()[True]\n",
    "# print tweets['sim'].value_counts()[True]\n",
    "# print tweets['ImpeachmentDay'].value_counts()[True]\n",
    "\n",
    "# print tweets[tweets['ImpeachmentDay'] == True]['ForaDilma'].value_counts()[True]\n",
    "# print tweets[tweets['ImpeachmentDay'] == True]['NaoVaiTerGolpe'].value_counts()[True]\n",
    "\n",
    "hashtags = ['ForaDilma', 'NaoVaiTerGolpe']\n",
    "tweets_by_hashtags = [tweets[tweets['ImpeachmentDay'] == True]['ForaDilma'].value_counts()[True], \n",
    "                      tweets[tweets['ImpeachmentDay'] == True]['NaoVaiTerGolpe'].value_counts()[True]]\n",
    "\n",
    "x_pos = list(range(len(hashtags)))\n",
    "width = 0.7\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.bar(x_pos, tweets_by_hashtags, width, alpha=1, color='sienna')\n",
    "ax.set_ylabel('Número de tweets'.decode('utf-8'), fontsize=20)\n",
    "ax.set_title('Ranking: ForaDilma vs. NaoVaiTerGolpe (Votação SIM x NÃO)'.decode('utf-8'),\n",
    "             fontsize=15, fontweight='bold')\n",
    "ax.set_xticks([p + 0.4 * width for p in x_pos])\n",
    "ax.set_xticklabels(hashtags)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_link(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return ''\n",
    "\n",
    "tweets['link'] = tweets['text'].apply(lambda tweet: extract_link(tweet))\n",
    "\n",
    "tweets_relevant = tweets[tweets['ImpeachmentDay'] == True]\n",
    "tweets_relevant_with_link = tweets_relevant[tweets_relevant['link'] != '']\n",
    "\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['TchauQuerida'] == True]['link']\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['ForaDilma'] == True]['link']\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['ForaCunha'] == True]['link']\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['NaoVaiTerGolpe'] == True]['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['moro'] = tweets['text'].apply(lambda tweet: word_in_text('moro', tweet))\n",
    "tweets['cunha'] = tweets['text'].apply(lambda tweet: word_in_text('cunha', tweet))\n",
    "tweets['bolsonaro'] = tweets['text'].apply(lambda tweet: word_in_text('bolsonaro', tweet))\n",
    "tweets['lula'] = tweets['text'].apply(lambda tweet: word_in_text('lula', tweet))\n",
    "tweets['temer'] = tweets['text'].apply(lambda tweet: word_in_text('temer', tweet))\n",
    "tweets['feliciano'] = tweets['text'].apply(lambda tweet: word_in_text('feliciano', tweet))\n",
    "\n",
    "hashtags = ['Sérgio Moro'.decode('utf-8'), 'Eduardo Cunha', 'Jair Bolsonaro', 'Lula', 'Michel Temer', 'Marcos Feliciano']\n",
    "tweets_by_hashtags = [tweets['moro'].value_counts()[True],\n",
    "                      tweets['cunha'].value_counts()[True],\n",
    "                      tweets['bolsonaro'].value_counts()[True],\n",
    "                      tweets['lula'].value_counts()[True],\n",
    "                      tweets['feliciano'].value_counts()[True],\n",
    "                      tweets['temer'].value_counts()[True]]\n",
    "\n",
    "plt.subplots(figsize=(8,8))\n",
    "colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'peachpuff', 'mediumturquoise']\n",
    "explode = (0.03, 0.03, 0.03, 0.05, 0.03, 0.03)\n",
    "plt.pie(tweets_by_hashtags, explode=explode, labels=hashtags, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.legend(tweets_by_hashtags, loc='best')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io, json\n",
    "\n",
    "def twitter_search(q, max_results=1000, **kw):\n",
    "    search_results = twitter_api.search.tweets(q=q, count=1000, **kw)\n",
    "    \n",
    "    statuses = search_results['statuses']\n",
    "    \n",
    "    max_results = min(10000, max_results)\n",
    "    \n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_resuts']\n",
    "        except KeyError, e:\n",
    "            break\n",
    "            \n",
    "        kwargs = dict([ kv.split('=')\n",
    "                        for kv in next_results[1:].split(\"&\") ])\n",
    "        \n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "        \n",
    "        if len(statuses) > max_results:\n",
    "            break\n",
    "            \n",
    "    return statuses\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "q = 'ForaInternetLimitada'\n",
    "results = twitter_search(twitter_api, q, max_results=1000)\n",
    "\n",
    "print json.dumps(results[0], indent=1)\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_json(filename, data):\n",
    "    with io.open('data/{0}.json'.format(filename),\n",
    "                 'w', encoding='utf-8') as f:\n",
    "            f.write(unicode(json.dumps(data, ensure_ascii=False)))\n",
    "    \n",
    "def load_json(filename):\n",
    "    with io.open('data/{0}.json'.format(filename),\n",
    "                  encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "\n",
    "q = 'ForaInternetLimitada'\n",
    "\n",
    "\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "results = twitter_search(twitter_api, q, max_results=1000)\n",
    "\n",
    "save_json(q, results)\n",
    "results = load_json(q)\n",
    "\n",
    "# print json.dumps(results, indent=1)\n",
    "\n",
    "# print json.dumps(br_trends, indent=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
