{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing Docker on Cloud! ;)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ds/local/lib/python2.7/site-packages/mpltools/style/__init__.py:42: FutureWarning: \n",
      "\n",
      "    The style-sheet functionality in mpltools has been integrated into\n",
      "    Matplotlib >= 1.4. This module will be removed in a future release.\n",
      "\n",
      "    Note that style-sheets used by `matplotlib.style` use the standard\n",
      "    Matplotlib rc-file syntax instead of the INI format used by `mpltools`.\n",
      "    This mostly means un-quoting strings and changing '=' to ':'.\n",
      "\n",
      "\n",
      "  \"\"\", FutureWarning)\n",
      "/opt/ds/local/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# from tweepy import OAuthHandler\n",
    "# from tweepy import API\n",
    "# from tweepy import Cursor\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "print 'OK!'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import rcParams\n",
    "from mpltools import style\n",
    "from matplotlib import dates\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import scipy\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import random\n",
    "\n",
    "print 'OK!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Seaborn plots\n",
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set_context(rc={\"figure.figsize\": (8, 4)})\n",
    "# for R lovers :)\n",
    "style.use('ggplot')\n",
    "rcParams['axes.labelsize'] = 9\n",
    "rcParams['xtick.labelsize'] = 9\n",
    "rcParams['ytick.labelsize'] = 9\n",
    "rcParams['legend.fontsize'] = 7\n",
    "# rcParams['font.family'] = 'serif'\n",
    "rcParams['font.serif'] = ['Computer Modern Roman']\n",
    "rcParams['text.usetex'] = False\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "print 'OK!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "tweets_data_path = 'data/peda.json'\n",
    "\n",
    "tweets_data = []\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "for line in tweets_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print len(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tweets = pd.DataFrame()\n",
    "\n",
    "tweets['created_at'] = map(lambda tweet: time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(tweet['created_at'],'%a %b %d %H:%M:%S +0000 %Y')), tweets_data)\n",
    "tweets['user'] = map(lambda tweet: tweet['user']['screen_name'], tweets_data)\n",
    "tweets['user_followers_count'] = map(lambda tweet: tweet['user']['followers_count'], tweets_data)\n",
    "tweets['retweet_count'] = map(lambda tweet: tweet['retweet_count'], tweets_data)\n",
    "tweets['favorite_count'] = map(lambda tweet: tweet['favorite_count'], tweets_data)\n",
    "\n",
    "print 'OK!'\n",
    "\n",
    "tweets.info()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame()\n",
    "\n",
    "tweets['text'] = map(lambda tweet: tweet['text'], tweets_data)\n",
    "tweets['lang'] = map(lambda tweet: tweet['lang'], tweets_data)\n",
    "tweets['country'] = map(lambda tweet: tweet['place']['country']\n",
    "                        if tweet['place'] != None else None, tweets_data)\n",
    "\n",
    "tweets_by_lang = tweets['lang'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.set_xlabel('Línguas'.decode('utf-8'), fontsize=20)\n",
    "ax.set_ylabel('Número de tweets'.decode('utf-8') , fontsize=20)\n",
    "ax.set_title('Top 4 Línguas'.decode('utf-8'), fontsize=20, fontweight='bold')\n",
    "tweets_by_lang[:4].plot(ax=ax, kind='bar', color='mediumspringgreen')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_by_country = tweets['country'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.set_xlabel('Países'.decode('utf-8'), fontsize=20)\n",
    "ax.set_ylabel('Número de tweets'.decode('utf-8') , fontsize=20)\n",
    "ax.set_title('Top 5 Países'.decode('utf-8'), fontsize=20, fontweight='bold')\n",
    "tweets_by_country[:5].plot(ax=ax, kind='bar', color='lightskyblue')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "tweets['NaoVaiTerGolpe'] = tweets['text'].apply(lambda tweet: word_in_text('NaoVaiTerGolpe', tweet))\n",
    "tweets['TchauQuerida'] = tweets['text'].apply(lambda tweet: word_in_text('TchauQuerida', tweet))\n",
    "tweets['ForaDilma'] = tweets['text'].apply(lambda tweet: word_in_text('ForaDilma', tweet))\n",
    "# tweets['BrasilContraOGolpe'] = tweets['text'].apply(lambda tweet: word_in_text('BrasilContraOGolpe', tweet))\n",
    "# tweets['ForaCunha'] = tweets['text'].apply(lambda tweet: word_in_text('ForaCunha', tweet))\n",
    "\n",
    "# print tweets['FicaQuerida'].value_counts()[True]\n",
    "# print tweets['NaoVaiTerGolpe'].value_counts()[True]\n",
    "# print tweets['ForaPT'].value_counts()[True]\n",
    "\n",
    "# hashtags = ['ForaDilma', 'NaoVaiTerGolpe', 'TchauQuerida', 'BrasilContraOGolpe', 'ForaCunha']\n",
    "hashtags = ['ForaDilma', 'NaoVaiTerGolpe', 'TchauQuerida']\n",
    "tweets_by_hashtags = [tweets['ForaDilma'].value_counts()[True],\n",
    "                      tweets['NaoVaiTerGolpe'].value_counts()[True],\n",
    "                      tweets['TchauQuerida'].value_counts()[True]]\n",
    "#                       tweets['BrasilContraOGolpe'].value_counts()[True],\n",
    "#                       tweets['ForaCunha'].value_counts()[True]]\n",
    "\n",
    "plt.subplots(figsize=(9,9))\n",
    "colors = ['gold', 'yellowgreen', 'lightcoral']\n",
    "explode = (0.03, 0.03, 0.03)\n",
    "plt.pie(tweets_by_hashtags, explode=explode, labels=hashtags, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.legend(tweets_by_hashtags, loc=(1,.6))\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['nao'] = tweets['text'].apply(lambda tweet: word_in_text('nao', tweet))\n",
    "tweets['sim'] = tweets['text'].apply(lambda tweet: word_in_text('sim', tweet))\n",
    "\n",
    "tweets['ImpeachmentDay'] = tweets['text'].apply(lambda tweet: word_in_text('sim', tweet) \n",
    "                                          or word_in_text('nao', tweet))\n",
    "\n",
    "# print tweets['nao'].value_counts()[True]\n",
    "# print tweets['sim'].value_counts()[True]\n",
    "# print tweets['ImpeachmentDay'].value_counts()[True]\n",
    "\n",
    "# print tweets[tweets['ImpeachmentDay'] == True]['ForaDilma'].value_counts()[True]\n",
    "# print tweets[tweets['ImpeachmentDay'] == True]['NaoVaiTerGolpe'].value_counts()[True]\n",
    "\n",
    "hashtags = ['ForaDilma', 'NaoVaiTerGolpe']\n",
    "tweets_by_hashtags = [tweets[tweets['ImpeachmentDay'] == True]['ForaDilma'].value_counts()[True], \n",
    "                      tweets[tweets['ImpeachmentDay'] == True]['NaoVaiTerGolpe'].value_counts()[True]]\n",
    "\n",
    "x_pos = list(range(len(hashtags)))\n",
    "width = 0.7\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.bar(x_pos, tweets_by_hashtags, width, alpha=1, color='sienna')\n",
    "ax.set_ylabel('Número de tweets'.decode('utf-8'), fontsize=20)\n",
    "ax.set_title('Ranking: ForaDilma vs. NaoVaiTerGolpe (Votação SIM x NÃO)'.decode('utf-8'),\n",
    "             fontsize=15, fontweight='bold')\n",
    "ax.set_xticks([p + 0.4 * width for p in x_pos])\n",
    "ax.set_xticklabels(hashtags)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_link(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return ''\n",
    "\n",
    "tweets['link'] = tweets['text'].apply(lambda tweet: extract_link(tweet))\n",
    "\n",
    "tweets_relevant = tweets[tweets['ImpeachmentDay'] == True]\n",
    "tweets_relevant_with_link = tweets_relevant[tweets_relevant['link'] != '']\n",
    "\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['TchauQuerida'] == True]['link']\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['ForaDilma'] == True]['link']\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['ForaCunha'] == True]['link']\n",
    "print tweets_relevant_with_link[tweets_relevant_with_link['NaoVaiTerGolpe'] == True]['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['moro'] = tweets['text'].apply(lambda tweet: word_in_text('moro', tweet))\n",
    "tweets['cunha'] = tweets['text'].apply(lambda tweet: word_in_text('cunha', tweet))\n",
    "tweets['bolsonaro'] = tweets['text'].apply(lambda tweet: word_in_text('bolsonaro', tweet))\n",
    "tweets['lula'] = tweets['text'].apply(lambda tweet: word_in_text('lula', tweet))\n",
    "tweets['temer'] = tweets['text'].apply(lambda tweet: word_in_text('temer', tweet))\n",
    "tweets['feliciano'] = tweets['text'].apply(lambda tweet: word_in_text('feliciano', tweet))\n",
    "\n",
    "hashtags = ['Sérgio Moro'.decode('utf-8'), 'Eduardo Cunha', 'Jair Bolsonaro', 'Lula', 'Michel Temer', 'Marcos Feliciano']\n",
    "tweets_by_hashtags = [tweets['moro'].value_counts()[True],\n",
    "                      tweets['cunha'].value_counts()[True],\n",
    "                      tweets['bolsonaro'].value_counts()[True],\n",
    "                      tweets['lula'].value_counts()[True],\n",
    "                      tweets['feliciano'].value_counts()[True],\n",
    "                      tweets['temer'].value_counts()[True]]\n",
    "\n",
    "plt.subplots(figsize=(8,8))\n",
    "colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'peachpuff', 'mediumturquoise']\n",
    "explode = (0.03, 0.03, 0.03, 0.05, 0.03, 0.03)\n",
    "plt.pie(tweets_by_hashtags, explode=explode, labels=hashtags, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.legend(tweets_by_hashtags, loc='best')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io, json\n",
    "\n",
    "def twitter_search(q, max_results=1000, **kw):\n",
    "    search_results = twitter_api.search.tweets(q=q, count=1000, **kw)\n",
    "    \n",
    "    statuses = search_results['statuses']\n",
    "    \n",
    "    max_results = min(10000, max_results)\n",
    "    \n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_resuts']\n",
    "        except KeyError, e:\n",
    "            break\n",
    "            \n",
    "        kwargs = dict([ kv.split('=')\n",
    "                        for kv in next_results[1:].split(\"&\") ])\n",
    "        \n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "        \n",
    "        if len(statuses) > max_results:\n",
    "            break\n",
    "            \n",
    "    return statuses\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "q = 'ForaInternetLimitada'\n",
    "results = twitter_search(twitter_api, q, max_results=1000)\n",
    "\n",
    "print json.dumps(results[0], indent=1)\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_json(filename, data):\n",
    "    with io.open('data/{0}.json'.format(filename),\n",
    "                 'w', encoding='utf-8') as f:\n",
    "            f.write(unicode(json.dumps(data, ensure_ascii=False)))\n",
    "    \n",
    "def load_json(filename):\n",
    "    with io.open('data/{0}.json'.format(filename),\n",
    "                  encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "\n",
    "q = 'ForaInternetLimitada'\n",
    "\n",
    "\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "results = twitter_search(twitter_api, q, max_results=1000)\n",
    "\n",
    "save_json(q, results)\n",
    "results = load_json(q)\n",
    "\n",
    "# print json.dumps(results, indent=1)\n",
    "\n",
    "# print json.dumps(br_trends, indent=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
