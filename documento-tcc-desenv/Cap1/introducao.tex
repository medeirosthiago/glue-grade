\chapter{INTRODUÇÃO}\label{ch:introducao}

Redes sociais se tornaram um termo comum e uma chave fundamental para o estilo de vida moderno. Hoje em dia, a maioria das pessoas, independente de idade, sexo, crença, utilizam uma ou mais redes sociais. A princípio, esses ambientes \textit{on-line} focavam-se na comunicação, por exemplo; a possibilidade de se comunicar com alguém distante e tornar esse diálogo pessoal, seguro e, de alguma forma, próximo, ajudando na popularização desse tipo de tecnologia. No decorrer dos anos e com o avanço tecnológico, diferentes tipos de redes sociais surgiram com ideias semelhantes ou extremamente diferentes, não sendo apenas para a comunicação, mas para outros fins como o compartilhamento de mídias, localização, críticas, \textit{mini-blogs}, perguntas e respostas, negócios, profissão, música, artes, venda e troca de produtos, entre outros.

\textit{Facebook}, \textit{Twitter}, \textit{LinkedIn}, \textit{Google+} e, muito comum entre desenvolvedores, o \textit{GitHub} são exemplos populares de redes sociais. Logo, possuem grande número de usuários e diversas interações que estes realizam a cada momento, gerando uma quantidade gigantesca de dados. Esses dados são informações sobre pessoas, comportamentos, gostos, marcas e vários outros tipos de conteúdo. Devido a diversidade e a vasta quantidade desse tipo de informação, algumas redes sociais as utilizam para o aprimoramento de conteúdo ou, então, para o comércio de dados para empresas, por exemplo; de publicidade e marketing, que fazem a mineração desses dados para encontrar padrões de seus usuários e, assim, conseguir aumentar suas vendas, reduzir riscos e, até mesmo, gerar novas tendências.

Dados é um termo, deliberadamente vago, que agrega várias formas comuns de informações, como por exemplo matrizes (vetores multidimensionais), tabelas ou planilhas, onde cada coluna pode ter um tipo diferente de informação (caracteres, numéricos, data, entre outros). Essas tabelas podem se relacionar através de colunas chaves apresentada no modelo relacional de \apudonline{codd}{data-command-line}.

Certamente que todos esses exemplos citados não demonstram a totalidade e nem toda a abordagem para a palavra dados. Não é sempre que grande percentual de um conjunto de dados pode ser transformados em uma forma estruturada, onde é possível serem analisados e modelados.

Cientistas de dados precisam visualizá-los com o objetivo de produzir resultados claros e serem capazes de informar ao seus mantenedores sobre a situação atual e a qualquer momento. Este é o verdadeiro valor que um cientista nessa área precisa prover.

A mineração de dados, também conhecida como \textit{data mining}, é o processo de analisar dados em diferentes perspectivas e transformar em informação útil. Hoje em dia, o \textit{data mining} é usado por companhias com grande foco em varejo, finanças, comunicação e marketing, para conseguirem determinar as relações de fatores internos como preço, posição de produto, ou habilidade de recurso humano, e fatores externos como indicadores econômicos, competições e população demográfica de clientes \cite{mining-social-web}.

Essa análise de dados consiste em visualizar informações em diferentes maneiras e formas, plotando gráficos e planilhas. Com isso, novas informações aparecerão permitindo alguma previsão ou predição desse conteúdo. As observações levarão a uma reflexão que resultará em possibilidades ou probabilidades concretas para se exercer uma atividade. No primeiro momento, essas informações são amorfas e, após a análise, se transformará em ideias \cite{han}.

Para que essas ideias se tornem um trabalho futuro é preciso capturá-las e interpretá-las através de um modelo de extração de conhecimento. Esse modelo, geralmente, é um processo que apresenta etapas que vão do armazenamento dos dados em estudos até processos matemáticos, estatísticos e computacionais, com o objetivo de extrair informações úteis. Um modelo então, é muito mais que apenas a descrição dos dados, incorpora o entendimento de todo o processo da origem dos dados até a competência deles. Logo, ele consegue fazer previsões sobre os conhecimentos analisados \cite{han}.

Para conseguir fazer melhores previsões é preciso desenvolver métodos mais sofisticados antes de formular um modelo relevante. Com isso, a dificuldade aumenta e, então, é necessário implementar um modelo computacional que consiga obter possíveis resultados através do reconhecimento desses dados.

Para a análise e a interação de dados, computação exploratória e visualização de dados, a linguagem de programação Python vai, inevitavalmente, ser comparada a muitas outras, tanto no domínio de software livre, como também, com linguagens e ferramentas comerciais, como R, MATLAB, SAS, Stata e outros. Atualmente, o Python possui bibliotecas que se tornaram fortes alternativas para a tarefa de manipulação de dados. Combinado com o poder de programação que a linguagem tem, é uma excelente escolha como linguagem para a construção de aplicações centradas em dados \cite{python-analysis}.

Em muitas organizações, é comum realizar pesquisas, prototipar e testar novas ideias utilizando mais de um domínio específico de linguagem computacional, como MATLAB ou R e, posteriormente, estas ideias viram parte de um sistema de produção maior, escrito, por exemplo, em Java, C\#, ou C++. \citeonline{kaldero}, afirma que Python não é somente uma linguagem adequada para a pesquisa e prototipagem, mas também para o desenvolvimento de sistemas.

Devido a esta solução de apenas uma única linguagem, as organizações podem se beneficiar, tendo cientistas e tecnólogos usando o mesmo conjunto de ferramentas programáticas. Portanto, Python é a ferramenta escolhida pela maioria desses profissionais. Essa escolha se deve, não somente a alta produtividade que a linguagem fornece, mas também por ela ser uma ferramenta comum a diferentes times e organizações \cite{kaldero}. 

Python é uma linguagem de programação livre e multiplataforma, possui uma excelente documentação e está sobre cuidado de uma enorme comunidade, onde é possível obter ajuda e melhores soluções para problemas durante a codificação. Tem como grande vantagem a facilidade de aprendizado, porque foi desenvolvida para ser simples e descomplicada. É uma linguagem interpretada, dinâmicamente tipada, com grande precisão e sintaxe eficiente. Tem grande popularidade para analisar dados devido ao enorme poder que suas bibliotecas possuem (\textit{NumPy}, \textit{SciPy}, \textit{pandas}, \textit{matplotlib}, \textit{IPython}). A linguagem apresenta alta produtividade para prototipação, desenvolvimento de sistemas menores e reaproveitáveis.

A mineração de dados busca então, extrair dos dados o conhecimento útil para algum objetivo específico. Entretanto, a tarefa de extração de conhecimento é complexa devido a multidisciplinaridade envolvida no seu processo de extração e, também, por não ter um modelo de mineração genérico para a busca de informação útil. Para isso, é necessário o uso de ferramentas que viabilizam essas tarefas. Logo, Python dispõe de um conjunto de bibliotecas para a análise e mineração de dados extremamente poderosas e com uma curva de aprendizado curta, graças a sintaxe clara e descomplicada que a linguagem fornece.


\section{JUSTIFICATIVA}\label{sec:justificativa}
This chapter kicks off our journey of mining the social web with Twitter, a rich source of social data that is a great starting point for social web mining because of its inherent openness for public consumption, clean and well-documented API, rich developer tooling, and broad appeal to users from every walk of life. Twitter data is particularly interesting because tweets happen at the “speed of thought” and are available for con‐ sumption as they happen in near real time, represent the broadest cross-section of so‐ ciety at an international level, and are so inherently multifaceted. Tweets and Twitter’s “following” mechanism link people in a variety of ways, ranging from short (but often meaningful) conversational dialogues to interest graphs that connect people and the things that they care about.

Since this is the first chapter, we’ll take our time acclimating to our journey in social web mining. However, given that Twitter data is so accessible and open to public scru‐ tiny, Chapter 9 further elaborates on the broad number of data mining possibilities by providing a terse collection of recipes in a convenient problem/solution format that can be easily manipulated and readily applied to a wide range of problems. You’ll also be able to apply concepts from future chapters to Twitter data

In the context of the current discussion, these are just a few observations that are gen‐ erally true of humanity. We have a deeply rooted need to share our ideas and experiences, which gives us the ability to connect with other people, to be heard, and to feel a sense of worth and importance. We are curious about the world around us and how to organize and manipulate it, and we use communication to share our observations, ask questions, and engage with other people in meaningful dialogues about our quandaries.

The last two bullet points highlight our inherent intolerance to friction. Ideally, we don’t want to have to work any harder than is absolutely necessary to satisfy our curiosity or get any particular job done; we’d rather be doing “something else” or moving on to the next thing because our time on this planet is so precious and short. Along similar lines, we want things now and tend to be impatient when actual progress doesn’t happen at the speed of our own thought.One way to describe Twitter is as a microblogging service that allows people to com‐ municate with short, 140-character messages that roughly correspond to thoughts or ideas. In that regard, you could think of Twitter as being akin to a free, high-speed, global text-messaging service. In other words, it’s a glorified piece of valuable infra‐ structure that enables rapid and easy communication. However, that’s not all of the story. It doesn’t adequately address our inherent curiosity and the value proposition that emerges when you have over 500 million curious people registered, with over 100 mil‐ lion of them actively engaging their curiosity on a regular monthly basis.

Besides the macro-level possibilities for marketing and advertising—which are always lucrative with a user base of that size—it’s the underlying network dynamics that created the gravity for such a user base to emerge that are truly interesting, and that’s why Twitter is all the rage. While the communication bus that enables users to share short quips at the speed of thought may be a necessary condition for viral adoption and sustained engagement on the Twitter platform, it’s not a sufficient condition. The extra ingredient that makes it sufficient is that Twitter’s asymmetric following model satisfies our curi‐ osity. It is the asymmetric following model that casts Twitter as more of an interest graph than a social network, and the APIs that provide just enough of a framework for struc‐ ture and self-organizing behavior to emerge from the chaos.In other words, whereas some social websites like Facebook and LinkedIn require the mutual acceptance of a connection between users (which usually implies a real-world connection of some kind), Twitter’s relationship model allows you to keep up with the latest happenings of any other user, even though that other user may not choose to follow you back or even know that you exist. Twitter’s following model is simple but exploits a fundamental aspect of what makes us human: our curiosity. Whether it be an infatuation with celebrity gossip, an urge to keep up with a favorite sports team, a keen interest in a particular political topic, or a desire to connect with someone new, Twitter provides you with boundless opportunities to satisfy your curiosity.


Para que os dados se tornem uma informação útil é preciso saber como coletar, processar, modelar e visualizar. Portanto, este estudo é tratado como uma área interdisciplinar que depende de uma arquitetura de \textit{software} apropriada, técnicas de processamento massivo de dados, algoritmos de redução de dimensionalidade, modelagem estatística e computacional, visualização de dados, entre outros.


\section{OBJETIVOS \textbf{\textcolor{red}{[REFAZER]}}}\label{sec:objetivos}

\subsection{Objetivo Geral} 
Este trabalho tem como objetivo principal utilizar técnicas e algoritmos de \textit{data mining}, como o aprendizado de máquina (\textit{machine learning}), para a análise e mineração de dados provenientes da rede social textit{Twitter}, utilizando os recursos e bibliotecas que a linguagem de programação Python possui.

\subsection{Objetivos Específicos}\label{subsec:objetivos_especificos}
\begin{itemize}
	\item Identificar os conceitos sobre KDD e \textit{data mining};
	\item Descrever as técnicas de \textit{data mining};
	\item Explorar as funcionalidades das bibliotecas de mineração e visualização da linguagem Python;
	\item Examinar e utilizar a API da rede social \textit{Twitter};
	\item Encontrar padrões utilizando técnicas e algoritmos de aprendizado de máquina (machine learning);
	\item Compreender e aplicar técnicas de geolocalização para melhor apresentação de resultados;
	\item Apresentar testes e resultados obtidos da análise e mineração dos dados.
\end{itemize}

\section{CRONOGRAMA DE ATIVIDADES}\label{subsec:cronograma}

As atividades a serem executadas no decorrer do projeto visando o êxito do mesmo, estão listados a seguir e especificados em meses na Tabela~\ref{cronograma}:

\begin{itemize}
  \item Estudo e Pesquisa: aquisição dos conhecimentos pertinentes e necessários para o desenvolvimento do projeto;
  \item Análise de Requisitos: levantamento dos requisitos do projeto;
  \item Geração de Documentação: desenvolvimento das documentações para especificação do projeto;
  \item Implementação: desenvolvimento dos códigos para a análise de dados;
  \item Testes: execução dos testes que irão garantir a qualidade das informações a serem geradas;
  \item Elaboração de Artigos: parte do tempo destinado ao projeto será para desenvolver artigos visando a publicação em eventos da área;
  \item Apresentação de Resultados: etapas destinadas à apresentação dos resultados parciais e finais.
\end{itemize}


\renewcommand{\arraystretch}{1.5}

%\begin{table}[h!]
%  \centering
%  \caption{Cronograma de execução}
%	\begin{adjustwidth}{-2cm}{}
%  \begin{tabular}{ | l | c | c | c | c | c | c | c | c | c | }
%    \hline
%    \textbf{Mês - Ano} & \textbf{08/15} & \textbf{09/15} & \textbf{10/15} & \textbf{11/15} & \textbf{12/15} & \textbf{02/16} & \textbf{03/16} & \textbf{04/16} & \textbf{05/16} \\ \hline
%    Estudo e Pesquisa & X & X & X & X & X & X & X & X &  \\ \hline
%    Análise de Requisitos & X & X & X & X & X & X & X & X &  \\ \hline
%    Geração do Documento & X & X & X & X & X & X & X & X & X \\ \hline
%    Implementação &  &  &  & X & X & X & X & X & X \\ \hline
%    Testes &  &  &  & X & X & X & X & X & X \\ \hline
%    Elaboração de Artigos &  &  & X & X & X &  &  & X & X \\ \hline
%    Apresentação de Resultados &  &  &  &  & X &  &  &  & X \\
%    \hline
%  \end{tabular}
%  	\end{adjustwidth}
%  \legend{\small{FONTE: Elaborado pelo autor}}
%  \label{cronograma}
%\end{table}

\begin{table}[h!]
	\centering
	\caption{Cronograma de execução}
	\includegraphics[width=1\textwidth]{Cap1/imagens/tabela}
%	\vspace{-0.3cm}
	\legend{FONTE: Elaborado pelo autor}
	\label{cronograma}
\end{table}


\section{ORGANIZAÇÃO DO TRABALHO}\label{sec:organizacao-trabalho}

Além deste capítulo introdutório, este trabalho é composto de mais seis capítulos.

O capítulo 2 apresenta os trabalhos que são referências para este estudo.

Os fundamentos teóricos, como os conceitos de \textit{data mining}, e base para o entendimento do tema proposto estão descritos no capítulo 3.

As bibliotecas da linguagem Python utilizadas para a mineração de dados são expostas no capítulo 4. Também, são apresentadas neste capítulo a API do \textit{LinkedIn}, as etapas de \textit{data mining} e outros materiais e metodologias utilizados para execução deste trabalho.

No capítulo 5 são demonstradas as fases de desenvolvimento de algoritmos para a implementação do \textit{data mining} e \textit{machine learning}.

Os resultados obtidos e a apresentação de planilhas e gráficos das soluções desenvolvidas são apresentados no capítulo 6.

Por fim, a conclusão deste trabalho se dá no capítulo 7, onde são abordadas e analisadas as dificuldades, além de determinar as possibilidades para trabalhos futuros.
